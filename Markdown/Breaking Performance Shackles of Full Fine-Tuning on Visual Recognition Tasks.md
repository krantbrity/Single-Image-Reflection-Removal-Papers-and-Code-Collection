# 5%>100%: 打破视觉识别任务全参数微调的性能枷锁

**作者**: Dongshuo Yin¹*, Leiyi Hu²*, Bin Li³, Youqun Zhang³, Xue Yang⁴†

¹清华大学计算机科学与技术系，BNRist  
²中国科学院大学  
³阿里巴巴集团  
⁴上海交通大学

*这些作者贡献相等  
†通讯作者

## 摘要

预训练与微调可以提高视觉任务的迁移效率和性能。最近的增量调优方法为视觉分类任务提供了更多选择。尽管取得了成功，但现有的视觉增量调优技术在具有挑战性的任务（如目标检测和分割）上未能超越全参数微调的上限。为了找到全参数微调的竞争性替代方案，我们提出了多认知视觉适配器（Mona）调优，这是一种新颖的基于适配器的调优方法。首先，我们在适配器中引入多个视觉友好的滤波器来增强其处理视觉信号的能力，而之前的方法主要依赖于语言友好的线性滤波器。其次，我们在适配器中添加缩放归一化层来调节视觉滤波器输入特征的分布。为了充分展示Mona的实用性和通用性，我们在多个代表性视觉任务上进行了实验，包括COCO上的实例分割、ADE20K上的语义分割、Pascal VOC上的目标检测、DOTA/STAR上的定向目标检测，以及三个常见数据集上的图像分类。令人兴奋的结果表明，Mona在所有这些任务上都超越了全参数微调，并且是唯一在上述各种任务上优于全参数微调的增量调优方法。例如，Mona在COCO数据集上相比全参数微调获得了1%的性能提升。综合结果表明，Mona调优比全参数微调更适合保留和利用预训练模型的能力。代码将在 https://github.com/Leiyi-Hu/mona 发布。

## 1. 引言

预训练与微调范式可以在同模态任务之间实现令人印象深刻的迁移学习，这在计算机视觉(CV)和自然语言处理(NLP)中已得到证明。预训练模型通常由资源充足且经验丰富的团队使用大量清洁数据进行训练。优秀的预训练模型可以帮助硬件和数据受限的团队节省大量训练成本，并在新任务上训练出性能良好的深度模型。在大模型时代，调优预训练模型的效率是一个重要问题。全参数微调在计算机视觉任务中被广泛使用并取得了巨大成功，它在训练过程中调优预训练主干网络中的所有参数以及额外的任务特定头部/颈部。许多令人印象深刻的计算机视觉技术通过预训练和全参数微调推动了视觉任务的极限。然而，全参数微调现在仍然是微调视觉任务的最佳方式吗？

除了全参数微调，增量调优最近在NLP和CV任务中引起了关注。增量调优来自NLP，它只调优主干网络的一部分或额外的轻量级结构以实现高效的迁移学习。增量调优方法通常固定大部分主干参数，并在简单任务（包括NLP和CV中的分类任务）上实现与全参数微调相当甚至更好的性能。VPT是第一个探索提示调优在视觉分类任务上潜力的工作。LoRand开创了在密集预测任务上的适配器调优，并缩小了增量调优与全参数微调在视觉任务上的差距。然而，现有方法无法在视觉识别任务（包括语义和实例分割）上优于全参数微调。

为了挑战全参数微调在CV中的主导地位，我们提出了Mona调优，这是一种基于多认知视觉适配器（Mona）的新颖调优范式。我们分析了最近的技术并总结了现有视觉适配器中的两个问题。首先，现有CV适配器的设计遵循NLP中的线性适配器。实际上，视觉任务处理视觉信号，这与语言信号显著不同，并且具有独特的2D卷积操作。我们的实验表明，基于卷积的滤波器可以更好地将视觉知识从预训练模型迁移到其他任务，因此我们为视觉任务提出了一个实用的基于卷积的适配器。其次，大多数现有适配器用单个线性层压缩上游特征。先前的工作声称模型对不同滤波器尺度的特征有不同的认知。因此，我们在适配器的降维层后采用多个卷积滤波器来增强适配器的认知能力。

我们在大量代表性视觉任务上展示了Mona调优的通用性和优越性，包括图像分类、目标检测、语义分割、实例分割和定向目标检测。我们采用在ImageNet-22k上训练的SwinTransformer系列作为预训练模型。广泛的实验表明，所提出的方法在简单的图像分类任务和复杂的视觉任务上都优于传统的全参数微调范式。例如，Mona调优在COCO数据集上比全参数微调高出1% mAP。结果表明，全参数微调可能不再是视觉任务的最佳选择。据我们所知，Mona是唯一在语义分割、实例分割和定向目标检测上超越全参数微调的基于适配器的调优方法。图1展示了所提出方法在具有挑战性的实例分割和语义分割任务上的优越性。

我们的贡献可以总结为三个方面：
- 我们证明了基于适配器的调优可以在视觉任务上超越全参数微调，并且用更少的新参数比全参数微调表现更好。
- 我们提出了Mona调优，这是一种基于多认知视觉适配器（Mona）的新颖且实用的训练范式。Mona采用视觉友好的滤波器来优化传统的线性适配器，并通过多个认知角度提高视觉预训练知识的迁移效率。
- 广泛的实验证明，Mona调优在代表性视觉任务上优于全参数微调和其他最新技术，包括图像分类、目标检测、语义分割、实例分割和定向目标检测。

## 2. 相关工作

### 2.1 增量调优

大模型的发展在整个人工智能领域产生了戏剧性的冲击。迁移学习的效率吸引了研究者的兴趣。增量调优（或参数高效微调，PEFT）致力于提高微调的效率。增量调优方法可以分为三组。第一组固定预训练主干中的大部分参数并微调少量参数，例如BitFit调优偏置，Norm Tuning调优归一化层，Partial-1只调优最后一个块。第二组重新参数化预训练模型中的一些参数，例如LoRA优化低秩子空间。第三组固定预训练主干的原始参数并添加额外的可训练结构，包括提示系列和适配器系列。我们的实验将Mona与这三组进行比较。

### 2.2 计算机视觉遇见增量调优

尽管来源于NLP，增量调优也在CV中得到了探索。VPT是第一个将增量调优（提示调优）引入视觉分类任务的工作。Chen等人为提高参数效率而非性能效率，将适配器添加到可训练主干。AdaptFormer设计了并行适配器结构来改善视觉分类上的增量调优性能。KAdaptation通过Kronecker乘积优化适配器。上述技术是视觉任务的先驱，揭示了增量调优在视觉分类上的潜力。LoRand通过多分支低秩适配器在密集预测任务上带来了令人印象深刻的性能，但仍不能在所有视觉识别任务上超越全参数微调。最近的技术表明，增量调优无法完全替代视觉任务上的全参数微调。因此，我们提出了Mona调优，这是更多视觉任务的全参数微调的替代方案，它在新参数大小和性能方面都优于全参数微调。

## 3. 方法

在本节中，我们分四个部分介绍所提出的方法，包括适配器调优、Mona和参数分析。

### 3.1 适配器调优

先前的工作讨论了适配器微调，我们在这里简要介绍相关概念。全参数微调更新预训练主干中的所有参数，而适配器调优固定预训练参数并更新适配器中的参数。对于数据集D = {(xi, yi)}ᴺᵢ₌₁，全参数微调和适配器调优的优化过程可以表示为等式1和等式2：

θ ← arg min loss(D, θ)                    (1)
      θ

ω ← arg min loss(D, θF, ω)                (2)
      ω

其中loss是训练损失，θ表示整个框架的参数，θF是适配器调优中的固定参数。ω表示适配器调优中的更新参数，包括适配器中的参数和主干外的参数。

### 3.2 Mona

典型的线性适配器在应用于视觉任务时面临两个问题。首先，固定层参数无法微调以匹配新任务的数据分布，导致传递给适配器的特征分布存在偏差。因此，适配器优化来自固定层的输入分布很重要。其次，传统适配器是为自然语言信号设计的，没有针对视觉信号进行优化。先前的CV适配器技术基于线性滤波器（主要包括降维投影、非线性激活、升维投影和跳跃连接），这对于迁移视觉知识来说效率不高。为了解决这两个问题，我们进行输入优化并设计多认知视觉滤波器。

**输入优化**。我们使Mona能够调整输入分布和来自固定层的输入比例。具体来说，我们在Mona的顶端添加一个归一化层和两个可学习权重s1和s2来调整输入分布。先前的工作表明，归一化有助于稳定前向输入分布和反向传播梯度。我们在实践中发现LayerNorm(LN)比BatchNorm更好，所以我们在Mona中采用LN。图2展示了我们的设计，可以表示为：

xnorm = s1 · |x0|LN + s2 · x0              (3)

其中|·|LN表示LayerNorm，x0表示Mona的原始输入。

**多认知视觉滤波器**。对于视觉认知，人眼从不同尺度处理视觉信号并将它们整合以获得更好的理解。适配器也应该从多个认知角度处理上游特征以在下游任务上获得更好的性能。我们向Mona引入多个卷积滤波器以增加认知维度。我们使用深度卷积（DWConv）而不是标准卷积来最小化额外的参数大小。具体来说，上游特征在降维投影后通过三个DWConv滤波器。卷积核大小分别为3×3、5×5和7×7。我们计算三个滤波器的平均结果并用1×1卷积聚合特征。跳跃连接被添加到两种类型的卷积中。我们使用三个深度卷积，权重为ωᵢdw ∈ ℝᶜᴰⁱⁿˣᴷⁱˣᴷⁱˣᶜᴰᵒᵘᵗ (i ∈ 1,2,3)用于第一个多滤波器卷积，以及一个点卷积，权重为ωⁱpw ∈ ℝᶜᴾⁱⁿˣ¹ˣ¹ˣᶜᴾᵒᵘᵗ用于第二个卷积。上述两个卷积步骤可以表示如下：

fdw = x + avg(∑³ᵢ₌₁ ωᵢdw⊗̂x)
fpw = x + ωpw⊗x                           (4)

其中⊗̂和⊗分别表示深度卷积和点卷积。然后，特征通过GeLU非线性化并通过升维投影恢复。Mona的整体计算过程可以表示如下：

x = x0 + Ulσ(fpw(fdw(Dl(xnorm))))        (5)

其中Dl和Ul表示第l个适配器的降维和升维投影，σ表示GeLU激活。

### 3.3 参数分析

Mona的参数来自LN、缩放因子、线性层、DWconv和1×1卷积。假设适配器的输入维度为m，降维投影后的维度为n，LN和缩放因子的参数为2m + 2，两个线性层的参数为2mn + m + n，DWConv层的参数为(3² + 5² + 7²)n = 83n，PWConv为n²。每个Mona模块的总参数为：

(2n + 3)m + n² + 84n + 2                  (6)

对于每个块，所有Mona参数为：2 × [(2n + 3)m + n² + 84n + 2]。我们将n的值设为常数（64）以减少Mona中的参数。

## 4. 实验

我们在多个代表性视觉任务上实施了充分的实验来证明Mona调优的优越性。本节包括实验设置、结果、收敛分析和一些消融实验。超参数和训练的详细设置在补充材料中呈现。

### 4.1 数据集

**目标检测**。Pascal VOC 0712包含16k/5k训练/验证图像，用于目标检测任务。我们采用Swin-Large + RetinaNet进行训练。目标检测任务的评估指标是最常用的APbox。

**语义分割**。ADE20K是最广泛使用的语义分割数据集，包含20K训练和2K验证图像。我们采用Swin-Large + UperNet进行语义分割实验。评估指标是最常用的mIoU。

**实例分割**。MS COCO是一个代表性的实例分割数据集，包含118k训练图像和5k验证图像。我们采用Swin-Base + Cascade Mask RCNN进行训练。实例分割任务的评估指标是APbox和APMask。

**定向目标检测**。定向目标检测在标注和推理过程中考虑角度信息，这可以有效提高遥感等领域目标检测的性能和效率。这项任务需要更准确的标注信息和更复杂的检测模型，比水平目标检测更具挑战性。选择了两个代表性的遥感数据集DOTA和STAR进行我们的实验。我们还在更具挑战性的STAR数据集上用多个检测框架进行实验。这里的指标是APbox。

**图像分类**。分类任务在以前的技术中得到了很好的研究。我们还在Oxford 102 Flower、Oxford-IIIT Pet和VOC 2007分类数据集上进行实验，以增加我们实验的广度。报告了每种方法的top-1、top-5和平均准确率。

### 4.2 预训练模型和工具包

所有实验都采用Swin Transformer系列作为主干。预训练模型在ImageNet-22k上训练，使用MMDetection、MMSegmentation、MMRotate和MMClassification等工具包进行验证。预训练任务的图像分辨率为224×224。大多数任务采用Swin-Large作为主干。考虑到这些任务的内存消耗，COCO、DOTA和STAR的主干采用Swin-Base。

### 4.3 基线方法

我们将Mona与多个最新方法进行比较。基线可以分为有或没有额外结构的方法：

**没有额外结构**：
- FULL：更新框架中的所有参数。
- FIXED：固定主干并更新其他参数。
- BITFIT：更新主干中的偏置和主干外的参数。
- NORMTUNING：更新主干中的归一化层和主干外的参数。
- PARTIAL-1：更新主干中的最后一个块和主干外的参数。

**有额外结构**：
（这些基线中的预训练层被固定，适配器中间维度都是64，遵循AdaptFormer）
- ADAPTER：在每个SwinBlock的MSA/MLP层后添加标准适配器层。
- LORA：向多头注意力权重添加并行可学习矩阵。
- ADAPTFORMER：向每个MLP层添加带有缩放权重的并行适配器层。
- LORAND：在每个SwinBlock的MSA/MLP后添加LoRand++（α=4，β=16）层。选择LoRand++是因为它在其变体中表现最好，所以选择最具挑战性的设置进行比较。

### 4.4 主要结果

COCO上的实例分割具有挑战性。从表1可以看出，Mona优于所有PEFT基线，是唯一超越全参数微调甚至高出1%的方法。COCO实验有效证明了所提出方法的能力，并在存储和性能方面显示了比全参数微调更好的选择。在增量调优方法中，大多数没有额外结构的基线可以节省更多新参数（除了Partial-1），但它们的平均性能低于有额外结构的方法。对于有额外结构的基线，基于适配器的方法优于基于重参数化的LoRA。表1显示LoRA在NLP任务上表现良好，但在计算机视觉任务上表现不佳。表1表明，增量调优的性能与参数大小没有直接关系。Partial-1有最多的可训练参数，但其性能明显低于基于适配器的基线。这个结果表明，优秀的模块设计可以有效增强预训练模型的迁移效率并减少大量新参数。

表2显示了Pascal VOC（目标检测）和ADE20K（语义分割）的结果。同样，Mona在表2中优于所有其他方法。Mona在这两个任务上分别比全参数微调高出3.6%和0.18%。表2再次表明，全参数微调不是视觉迁移学习的最佳选择。有趣的是，所有基线都在VOC上超越了全参数微调，这与COCO和ADE20K不同。VOC中相对较少的数据可能导致在微调198M Swin-Large预训练模型时过拟合。与全参数微调相比，其他方法固定大多数预训练参数，所以模型性能在调优过程中不太可能严重崩溃。NLP学者将类似情况视为低资源情况。这里的VOC可以被视为CV中的低资源情况。对于ADE20K，没有额外结构的基线和基于适配器的基线之间的性能差距比VOC和COCO更显著。对于参数大小，表1和2中的大多数方法（除了Partial-1）产生少于5%的新主干参数，这是增量调优的特征。尽管参数略有增加，Mona仍然优于先前的技术，并大幅打破了全参数微调的性能上限。

表3显示了在更具挑战性的定向目标检测任务上的性能。首先，表3的第2-3列显示Mona在两个数据集上用Oriented R-CNN优于全参数微调和其他高效微调方法。其次，STAR比DOTA有更多实例和类别，比DOTA更具挑战性。所以我们在STAR上用更多框架进行实验。第4-5列显示了所有方法用KLD和H2RBox-v2的结果。可以看到Mona在这些框架上优于所有基线方法。表3进一步说明了所提出的适配器可以在更广泛的视觉任务上带来性能突破。

对于分类任务，我们在表4中显示了三个分类数据集的个别和平均结果。Mona在Flowers102和OxfordPets上优于所有基线，并优于所有基线的平均结果。表4表明Mona在相对简单的任务上具有高迁移效率。此外，我们发现所有增量调优方法的平均结果都超越了全参数微调，这与先前技术中的结论相似。与分类相比，复杂的密集预测任务可以更直观地展示不同调优方法的优缺点。

总结，表1到3的结果可以从两个方面总结：1）在性能方面，像Swin这样的技术中广泛使用的全参数微调范式不再是视觉任务的最优选择。所提出的Mona调优在代表性任务（如实例分割、语义分割、目标检测、图像分类和定向目标检测）中超越了全参数微调的性能上限。具体来说，Mona在具有挑战性的COCO实例分割任务中比全参数微调获得1% AP增益。2）基于多认知视觉滤波的Mona在大多数任务中超越了最近的杰出基线。Mona全面增强了增量调优在视觉任务中的实用性和通用性。Mona调优不仅显著降低了存储成本，还进一步提升了视觉任务的性能上限。

### 4.5 损失分析

我们在图3中展示了Mona和五个代表性基线在目标检测任务（Pascal VOC）上的损失收敛过程。与全参数微调相比，所提出的方法在收敛过程中产生了显著优势，这解释了它在VOC上的更好性能。Mona也比其他增量调优方法收敛更快，表明多认知视觉滤波器可以更好地处理视觉特征并加速迁移学习的收敛。收敛分析再次证明了所提出的方法是一种高度竞争的视觉迁移学习方法，全参数微调不再是视觉任务的最优选择。

### 4.6 消融实验

在本节中，我们消融影响模型性能的多个潜在因素，包括适配器的中间维度和模型大小。所有消融实验都在Pascal VOC上进行。

适配器的工作流程是将来自预训练层的输入压缩到低维特征空间，并通过调优适配器来迁移预训练知识。因此，中间维度对适配器很重要。我们在表5中消融Mona的中间维度并固定其他设置。维度候选是32、64和128。表5显示64维超越32维和128维。Chen等人也研究了AdaptFormer的中间维度。他们发现64维AdaptFormer在视觉分类任务上超越其32维和256维版本，这与我们的结论一致。表5和Chen等人的结果表明，适配器的中间维度与性能不成正比，这意味着更大数量的适配器参数不一定会导致更好的结果。

在表6中，我们在相同设置下改变主干网络的大小，模型候选是29M Swin-T、88M Swin-B和197M Swin-L。我们可以从表6得出以下三个结论。首先，主干网络参数越多，相同Mona设置下Mona参数的比例越小。这个结果表明，当主干变大时，Mona调优可以节省更多参数。现有的视觉模型越来越大。InternImage-H达到1.08B参数，SwinV2-G达到3B。参数高效的Mona调优在大模型时代可以节省数十亿参数和大量存储成本。其次，Mona在三种模型设置上都超越了全参数微调，当模型大小增长时其性能提高。表6显示Mona调优可以提高较小模型的训练效率和性能。我们刚刚讨论了Mona对大模型的优势。然而，更多资源受限的研究团队和项目组使用小模型。Mona调优也有潜力帮助资源受限的研究者在自己的应用中利用高性能大模型。第三，与全参数微调相比，所提出的方法更能够激发大模型的潜力。从Swin-T到Swin-L，全参数微调带来3.6%性能增益，而Mona带来3.8%。换句话说，Mona可以随着模型变大表现更好，并帮助进一步提高性能敏感任务的上限。

### 4.7 讨论

推理成本是行业关心的问题。基于适配器模块的方法（如Adapter、AdaptFormer、LoRand和Mona）引入了额外结构，伴随着推理成本的小幅增加。基于重参数化的方法（如LoRA）不影响推理成本，但在视觉任务上表现不佳。结合两种方法的优势可以大大增强适配器的实用性。我们将继续努力实现这个目标。

## 5. 结论

本文提出了一种新颖的视觉微调方法，即多认知视觉适配器（Mona）调优，它有效地提高了视觉微调的效率和性能。综合实验证明，所提出的Mona在代表性任务上优于传统的全参数微调范式和其他增量调优方法，包括实例分割、语义分割、目标检测、图像分类和定向目标检测。在大模型时代，全参数微调不再是视觉任务的最优选择。我们希望Mona调优可以提高大模型的知识迁移效率，并在更多视觉任务上带来性能突破。

## 参考文献

[此处包含完整的参考文献列表，包含所有引用的论文和技术报告]

### 表格和图片说明

**图1**：我们的方法与全参数微调和最新增量调优技术在代表性视觉任务上的比较。蓝色虚线是全参数微调在ADE20K和COCO上的性能。所提出的Mona在代表性视觉任务上优于全参数微调，提升了先前增量调优技术的上限。结果表明，适配器调优范式可以替代全参数微调并在常见视觉任务中获得更好的性能。全参数微调可能不再是未来迁移学习的唯一首选解决方案。

**图2**：左：所提出的Mona调优。我们在每个SwinBlock中的MSA和MLP后添加Mona。所提出的方法固定预训练层的参数并更新Mona的参数。右：Mona的详细信息。Mona在降维投影前有一个缩放LayerNorm。多认知卷积滤波器组和聚合滤波器在降维投影后。我们在Mona内部的四个地方添加跳跃连接以增强其适应能力。Mona使基于适配器的微调范式能够在典型视觉任务中全面优于全参数微调。

**图3**：损失曲线。在所有方法中，所提出的方法收敛更快并显著超越全参数微调。

**表1**：我们的方法与基线在COCO基准上的结果。这里采用Swin-B作为预训练模型。我们在左边展示可训练主干参数的数量和百分比，在右边展示所有性能。*表示主干中的可训练参数。每列中的最佳AP以粗体显示。

**表2**：我们的方法与基线在Pascal VOC和ADE20K基准上的结果。这里采用Swin-L作为预训练模型。我们在左边展示可训练主干参数的数量和百分比，在右边展示所有性能。*表示主干中的可训练参数。每列中的最佳AP/mIoU以粗体显示。

**表3**：DOTA和STAR基准上的结果。这里采用Swin-B作为预训练模型。每列中的最佳AP以粗体显示。

**表4**：我们的方法与基线在三个分类数据集上的结果。这里采用Swin-L作为预训练模型。我们展示每个数据集的top-1准确率(%)和top-5准确率(%)。每列中的最佳结果以粗体显示。

**表5**：中间维度的消融实验。64个中间维度获得最佳性能。*表示主干中的可训练参数。

**表6**：mona在不同大小模型上的性能。结果表明模型大小不限制Mona的优越性。
